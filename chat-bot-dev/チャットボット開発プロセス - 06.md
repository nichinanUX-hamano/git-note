---
date: 2025-07-21
tags:
  - 営業
  - API
Gemini: https://g.co/gemini/share/33ba7deb7ae8
release: https://g.co/gemini/share/0b37e90a6003
---
## Web実装（テスト）

このチャットボットをウェブサイトに実装するフローは、大きく分けて2つのアプローチがあります。

1. **最も手軽で迅速な方法:** PythonだけでUIまで構築できるライブラリを使う
    
2. **標準的で柔軟な方法:** バックエンドAPIとフロントエンドを分離して構築する
    

今回は、それぞれのフローをステップごとに説明します。

---

### アプローチ1: StreamlitやGradioを使う（迅速なプロトタイプ向け）

この方法は、Pythonのコードをほとんど変更することなく、簡単なWeb UIをすぐに作成できるため、デモや社内ツールとして非常に適しています。

**フロー:**

#### ステップ1: 必要なライブラリのインストール

StreamlitまたはGradioをインストールします。

Bash

```
pip install streamlit # または pip install gradio
```

#### ステップ2: コードの変更

これまでの `chat_bot.py` のコードを、StreamlitのUIコンポーネントに合わせて変更します。

**`app.py` （Streamlitの例）**

Python

```
# app.py

import os
from dotenv import load_dotenv
import streamlit as st
# 他の必要なライブラリをインポート
from langchain_community.document_loaders import DirectoryLoader, UnstructuredFileLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_community.vectorstores import Chroma
from langchain.chains import RetrievalQA
from langchain_core.prompts import PromptTemplate

# 1. 環境変数のロード
load_dotenv()
google_api_key = os.getenv("GOOGLE_API_KEY")
if not google_api_key:
    st.error("GOOGLE_API_KEY not found in .env file.")
    st.stop()

# 2. ベクトルデータベースのロード
vector_db_path = "./vector_db_data"
@st.cache_resource
def get_vectorstore():
    embeddings_model = GoogleGenerativeAIEmbeddings(model="models/embedding-001", google_api_key=google_api_key)
    return Chroma(persist_directory=vector_db_path, embedding_function=embeddings_model)

# 3. LLMとRAGチェーンの初期化
@st.cache_resource
def get_qa_chain():
    llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash", temperature=0.3, google_api_key=google_api_key)
    vectorstore = get_vectorstore()
    retriever = vectorstore.as_retriever(search_kwargs={"k": 3})

    # プロンプトテンプレートの定義
    prompt_template = """... (上記同様のテンプレート) ..."""
    PROMPT = PromptTemplate(template=prompt_template, input_variables=["context", "question"])

    return RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=retriever,
        return_source_documents=True,
        chain_type_kwargs={"prompt": PROMPT}
    )

# 4. Streamlit UI
st.title("NotebookLM 資料チャットボット")
qa_chain = get_qa_chain()

# セッション状態にチャット履歴を保存
if "messages" not in st.session_state:
    st.session_state.messages = []

# 過去のメッセージを表示
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ユーザーからの入力を受け付け
if prompt := st.chat_input("質問を入力してください"):
    # ユーザーの質問をチャット履歴に追加
    st.session_state.messages.append({"role": "user", "content": prompt})
    # ユーザーの質問をUIに表示
    with st.chat_message("user"):
        st.markdown(prompt)

    # AIの回答を生成
    with st.chat_message("assistant"):
        with st.spinner("回答を生成中..."):
            result = qa_chain.invoke({"query": prompt})
            response = result["result"]
            st.markdown(response)
            
            # 参照元ドキュメントを表示
            st.markdown("---")
            st.markdown("**参照元ドキュメント:**")
            for i, doc in enumerate(result.get("source_documents", [])):
                st.markdown(f"- **{doc.metadata.get('source', '不明なソース')}**")

    # AIの回答をチャット履歴に追加
    st.session_state.messages.append({"role": "assistant", "content": response})

```

#### ステップ3: アプリケーションの実行

ターミナルで以下のコマンドを実行するだけで、ウェブサイトが起動します。

Bash

```
streamlit run app.py
```

ローカルで起動したURL（通常 `http://localhost:8501`）にアクセスすれば、チャットボットをブラウザで利用できます。

---

### アプローチ2: バックエンドAPIとフロントエンドを分離（標準的な方法）

この方法は、より柔軟な設計と拡張性を持ち、プロダクション環境での運用に適しています。バックエンド（Python）がAPIとして機能し、フロントエンド（HTML/CSS/JS）がそのAPIを呼び出す形です。

**フロー:**

#### ステップ1: バックエンドAPIの構築 (Flask/FastAPI)

`chat_bot.py` のロジックを、HTTPリクエストを受け付けてJSONレスポンスを返すWeb APIとしてラップします。

**`api.py` （Flaskの例）**

Python

```
# pip install Flask
from flask import Flask, request, jsonify
import os
from dotenv import load_dotenv
# ... 他の必要なライブラリをインポート ...

# 1. 環境変数のロード
load_dotenv()
google_api_key = os.getenv("GOOGLE_API_KEY")

# 2. ベクトルデータベース、LLM、QAチェーンの初期化
# この初期化処理は、アプリケーションの起動時に一度だけ実行されるようにしておく
vector_db_path = "./vector_db_data"
embeddings_model = ...
vectorstore = Chroma(persist_directory=vector_db_path, embedding_function=embeddings_model)
llm = ...
qa_chain = RetrievalQA.from_chain_type(...)

# 3. Flaskアプリケーションの作成
app = Flask(__name__)

# 4. APIエンドポイントの定義
@app.route("/ask", methods=["POST"])
def ask_question():
    data = request.get_json()
    user_query = data.get("query")

    if not user_query:
        return jsonify({"error": "No query provided"}), 400

    try:
        result = qa_chain.invoke({"query": user_query})
        response = {
            "answer": result["result"],
            "source_documents": [doc.metadata.get("source", "N/A") for doc in result.get("source_documents", [])]
        }
        return jsonify(response)
    except Exception as e:
        return jsonify({"error": str(e)}), 500

# アプリケーションの実行
if __name__ == "__main__":
    app.run(debug=True, host="0.0.0.0", port=5000)

```

#### ステップ2: フロントエンドの構築 (HTML/CSS/JS)

シンプルなHTMLファイルを作成し、JavaScriptで上記のAPIエンドポイントに`POST`リクエストを送信するロジックを記述します。

**`index.html`**

HTML

```
<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <title>チャットボット</title>
    <style>/* スタイルは省略 */</style>
</head>
<body>
    <div id="chat-container">
        <div id="messages"></div>
        <form id="chat-form">
            <input type="text" id="user-input" placeholder="質問を入力..." />
            <button type="submit">送信</button>
        </form>
    </div>
    <script>
        const chatForm = document.getElementById('chat-form');
        const userInput = document.getElementById('user-input');
        const messagesContainer = document.getElementById('messages');

        chatForm.addEventListener('submit', async (e) => {
            e.preventDefault();
            const query = userInput.value;
            if (!query) return;

            // ユーザーのメッセージを表示
            messagesContainer.innerHTML += `<div class="user-message">あなた: ${query}</div>`;

            // APIにリクエストを送信
            const response = await fetch('/ask', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ query: query })
            });

            const data = await response.json();
            
            // AIの回答を表示
            if (response.ok) {
                messagesContainer.innerHTML += `<div class="ai-message">AI: ${data.answer}</div>`;
                // ソースドキュメントも表示
            } else {
                messagesContainer.innerHTML += `<div class="error-message">エラー: ${data.error}</div>`;
            }
            userInput.value = '';
            messagesContainer.scrollTop = messagesContainer.scrollHeight;
        });
    </script>
</body>
</html>
```

#### ステップ3: 実行とデプロイ

Flaskアプリを起動し、フロントエンドにアクセスしてテストします。本番環境へのデプロイには、Dockerコンテナ化してGoogle Cloud Runなどのサーバーレスプラットフォームを利用するのが一般的です。

### どちらのアプローチを選ぶべきか？

||**アプローチ1（Streamlit/Gradio）**|**アプローチ2（Flask/FastAPI）**|
|---|---|---|
|**開発速度**|非常に速い|少し時間がかかる|
|**学習コスト**|低い（Pythonのみ）|中（Python+JS+Webの基礎）|
|**柔軟性**|限定的（UIのカスタマイズが難しい）|高い（自由にデザイン可能）|
|**スケーラビリティ**|限定的|高い|
|**用途**|プロトタイプ、社内ツール、デモ|本番環境のWebサービス|

まずは**Streamlit**を使って、手軽に動作確認をしてみることをお勧めします。その後、必要に応じてFlaskやFastAPIを使った本格的なウェブアプリケーションに移行するのが良いでしょう。